<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Beats - AI Music Player</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

    <style>
        body {
            font-family: 'Orbitron', sans-serif;
            background: #0a192f;
            color: #64ffda;
        }
        .neon-border {
            box-shadow: 0 0 10px #64ffda, 0 0 20px #64ffda, 0 0 30px #64ffda;
        }
        .cyberpunk-gradient {
            background: linear-gradient(45deg, #0a192f, #112240);
        }
        #videoElement {
            transform: scaleX(-1);
        }
        .glow-text {
            text-shadow: 0 0 10px #64ffda;
        }
        .album-art {
            box-shadow: 0 0 15px rgba(100, 255, 218, 0.5);
        }
    </style>
</head>
<body class="min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <!-- Header -->
        <header class="text-center mb-10">
            <h1 class="text-4xl md:text-6xl font-bold glow-text mb-4">Neural Beats</h1>
            <p class="text-xl text-cyan-300">AI-Powered Music Experience</p>
        </header>

        <!-- Main Content -->
        <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
            <!-- Camera Feed Section -->
            <div class="cyberpunk-gradient rounded-lg p-4 neon-border">
                <h2 class="text-2xl mb-4">Emotion Detection</h2>
                <div class="relative">
                    <video id="videoElement" class="w-full h-64 object-cover rounded-lg mb-4" autoplay></video>
                    <div id="emotion-result" class="text-xl mt-4"></div>
                    <button id="startCamera" class="bg-cyan-500 hover:bg-cyan-600 text-white px-6 py-2 rounded-full mt-4">
                        <i class="bi bi-camera-fill mr-2"></i>Start Camera
                    </button>
                </div>
            </div>

            <!-- Music Player Section -->
            <div class="cyberpunk-gradient rounded-lg p-4 neon-border">
                <div class="flex flex-col items-center">
                    <div class="w-48 h-48 rounded-lg overflow-hidden mb-4 album-art">
                        <img id="albumArt" src="https://images.unsplash.com/photo-1470225620780-dba8ba36b745" class="w-full h-full object-cover" alt="Album Art">
                    </div>
                    <h3 id="songTitle" class="text-xl mb-2">Loading...</h3>
                    <p id="artistName" class="text-cyan-300 mb-4">Artist</p>
                    
                    <!-- Player Controls -->
                    <div class="flex items-center space-x-6">
                        <button class="text-3xl hover:text-cyan-300"><i class="bi bi-skip-backward-fill"></i></button>
                        <button id="playPause" class="text-4xl hover:text-cyan-300"><i class="bi bi-play-circle-fill"></i></button>
                        <button class="text-3xl hover:text-cyan-300"><i class="bi bi-skip-forward-fill"></i></button>
                    </div>
                    
                    <!-- Progress Bar -->
                    <div class="w-full mt-4">
                        <div class="bg-gray-700 rounded-full h-2">
                            <div class="bg-cyan-500 rounded-full h-2" style="width: 45%"></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Search Section -->
        <div class="mt-8 cyberpunk-gradient rounded-lg p-4 neon-border">
            <div class="flex flex-col md:flex-row gap-4">
                <div class="flex-1">
                    <div class="relative">
                        <input type="text" placeholder="Search for songs..." class="w-full bg-gray-800 text-white px-4 py-2 rounded-lg focus:outline-none focus:ring-2 focus:ring-cyan-500">
                        <button class="absolute right-2 top-2 text-cyan-500 hover:text-cyan-300">
                            <i class="bi bi-search"></i>
                        </button>
                    </div>
                </div>
                <button id="voiceSearch" class="bg-cyan-500 hover:bg-cyan-600 text-white px-6 py-2 rounded-lg">
                    <i class="bi bi-mic-fill mr-2"></i>Voice Search
                </button>
            </div>
        </div>
    </div>

    <script>
        // Camera functionality
        const video = document.getElementById('videoElement');
        const startButton = document.getElementById('startCamera');
        const emotionResult = document.getElementById('emotion-result');
        const playPauseBtn = document.getElementById('playPause');
        const voiceSearchBtn = document.getElementById('voiceSearch');
        let isPlaying = false;

        startButton.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                startEmotionDetection();
            } catch (err) {
                console.error('Error accessing camera:', err);
                emotionResult.textContent = 'Camera access denied';
            }
        });

        // Simulated emotion detection
        async function startEmotionDetection() {
            const emotions = ['Happy', 'Sad', 'Energetic', 'Calm', 'Excited'];
            setInterval(() => {
                const randomEmotion = emotions[Math.floor(Math.random() * emotions.length)];
                emotionResult.textContent = `Detected Emotion: ${randomEmotion}`;
                // Here you would implement actual ML-based emotion detection
            }, 3000);
        }

        // Play/Pause functionality
        playPauseBtn.addEventListener('click', () => {
            isPlaying = !isPlaying;
            playPauseBtn.innerHTML = isPlaying ? 
                '<i class="bi bi-pause-circle-fill"></i>' : 
                '<i class="bi bi-play-circle-fill"></i>';
        });

        // Voice Search functionality
        voiceSearchBtn.addEventListener('click', () => {
            if ('webkitSpeechRecognition' in window) {
                const recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;

                recognition.onstart = () => {
                    voiceSearchBtn.innerHTML = '<i class="bi bi-mic-fill mr-2"></i>Listening...';
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    document.querySelector('input[type="text"]').value = transcript;
                };

                recognition.onend = () => {
                    voiceSearchBtn.innerHTML = '<i class="bi bi-mic-fill mr-2"></i>Voice Search';
                };

                recognition.start();
            } else {
                alert('Voice recognition is not supported in this browser.');
            }
        });

        // Responsive design checks
        function checkDevice() {
            if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
                // Mobile-specific adjustments
                video.style.height = '240px';
            }
        }

        window.onload = checkDevice;
    </script>
<script>document.body.addEventListener('wheel', e => { if (!e.ctrlKey) return; e.preventDefault(); return }, { passive: false })</script>
	</body>
</html>